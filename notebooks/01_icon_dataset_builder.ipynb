{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e3032de",
   "metadata": {},
   "source": [
    "#### Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a2714a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiwon-hae/miniforge3/envs/icongen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from transformers import AutoProcessor, LlavaForConditionalGeneration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbf1ff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00, 30.34it/s]\n",
      "/home/jiwon-hae/miniforge3/envs/icongen/lib/python3.10/site-packages/torch/cuda/__init__.py:435: UserWarning: \n",
      "    Found GPU0 NVIDIA GB10 which is of cuda capability 12.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (8.0) - (12.0)\n",
      "    \n",
      "  queued_call()\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Choose the best open-weight annotation \n",
    "LLAVA_MODEL = \"llava-hf/llava-1.5-7b-hf\"\n",
    "model = LlavaForConditionalGeneration.from_pretrained(\n",
    "    LLAVA_MODEL, \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True, \n",
    ").to(0)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(LLAVA_MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3572d3",
   "metadata": {},
   "source": [
    "##### Configure Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb8601e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_DIR = Path(\"../data/stickers_png\")     # Each folder contains frame_XXXXX.png\n",
    "OUT_DIR = Path(\"../data/icons_256\")        # Flattened deduped dataset\n",
    "META_PATH = Path(\"../data/icons_metadata.jsonl\")\n",
    "\n",
    "OUT_DIR.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95099fca",
   "metadata": {},
   "source": [
    "##### Process All Stickers -> Resize + Depublicate + Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "326a3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_image_llava(img: Image.Image, prompt=\"Describe this icon in detail.\"):\n",
    "    # Build conversation prompt for LLaVA-HF\n",
    "    full_prompt = f\"USER: <image>\\n{prompt}\\nASSISTANT:\"\n",
    "\n",
    "    inputs = processor(\n",
    "        text=full_prompt,\n",
    "        images=img,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=120\n",
    "    )\n",
    "\n",
    "    return processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "def annotate_batch_llava(images, prompts):\n",
    "    \"\"\"\n",
    "    images: list[PIL.Image]\n",
    "    prompts: list[str] – same length as images\n",
    "    \"\"\"\n",
    "    # Format prompts with proper LLaVA conversation format\n",
    "    full_prompts = [f\"USER: <image>\\n{prompt}\\nASSISTANT:\" for prompt in prompts]\n",
    "    \n",
    "    # Preprocess multimodal batch\n",
    "    inputs = processor(\n",
    "        text=full_prompts,\n",
    "        images=images,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    ).to(model.device)\n",
    "\n",
    "    with torch.cuda.amp.autocast(dtype=torch.float16):\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=120\n",
    "        )\n",
    "\n",
    "    # Decode each generated caption\n",
    "    captions = processor.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    return captions\n",
    "\n",
    "def is_duplicate(phash, seen_hashes, threshold=5):\n",
    "    \"\"\"\n",
    "    phash       : imagehash object for current frame\n",
    "    seen_hashes : list of previous perceptual hashes\n",
    "    threshold   : Hamming distance threshold for perceptual duplicates\n",
    "    \"\"\"\n",
    "    for prev in seen_hashes:\n",
    "        if phash - prev < threshold:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcc58e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing packs:   0%|          | 0/237 [00:00<?, ?it/s]/tmp/ipykernel_444862/1287742095.py:34: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(dtype=torch.float16):\n",
      "Processing packs: 100%|██████████| 237/237 [1:16:09<00:00, 19.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 5865 images in 4582.02 sec\n",
      "Throughput: 1.28 images/sec\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "total_images = 0\n",
    "start_time = time.time()\n",
    "gpu_logs = []\n",
    "\n",
    "all_metadata = []\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "TARGET_SIZE = 256\n",
    "\n",
    "for sticker_dir in tqdm(list(SRC_DIR.iterdir()), desc=\"Processing packs\"):\n",
    "    if not sticker_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    frames = sorted(sticker_dir.glob(\"*.png\"))\n",
    "    if not frames:\n",
    "        continue\n",
    "\n",
    "    sticker_name = sticker_dir.name\n",
    "    seen_hashes = []\n",
    "    batch_images = []\n",
    "    batch_paths = []\n",
    "\n",
    "    saved_count = 0\n",
    "\n",
    "    for frame_path in frames:\n",
    "        try:\n",
    "            img = Image.open(frame_path).convert(\"RGBA\")\n",
    "        except:\n",
    "            print(\"Skipping corrupted image:\", frame_path)\n",
    "            continue\n",
    "\n",
    "        img = img.resize((TARGET_SIZE, TARGET_SIZE), Image.LANCZOS)\n",
    "\n",
    "        # perceptual dedupe\n",
    "        ph = imagehash.phash(img)\n",
    "        if is_duplicate(ph, seen_hashes):\n",
    "            continue\n",
    "\n",
    "        seen_hashes.append(ph)\n",
    "\n",
    "        # save resized version\n",
    "        out_filename = f\"{sticker_name}_{saved_count:05d}.png\"\n",
    "        img.save(OUT_DIR / out_filename)\n",
    "\n",
    "        batch_images.append(img)\n",
    "        batch_paths.append((out_filename, frame_path.name))\n",
    "        saved_count += 1\n",
    "        total_images += 1\n",
    "\n",
    "        # ---- If batch full, run LLaVA ----\n",
    "        if len(batch_images) == BATCH_SIZE:\n",
    "            prompts = [\"Describe this icon in detail.\"] * BATCH_SIZE\n",
    "            captions = annotate_batch_llava(batch_images, prompts)\n",
    "\n",
    "            # record performance\n",
    "            gpu_logs.append({\n",
    "                \"time\": time.time(),\n",
    "                \"gpu_util\": torch.cuda.utilization(),\n",
    "                \"mem\": torch.cuda.memory_allocated()\n",
    "            })\n",
    "\n",
    "            for (out_filename, orig_name), caption in zip(batch_paths, captions):\n",
    "                all_metadata.append({\n",
    "                    \"image\": out_filename,\n",
    "                    \"original_frame\": orig_name,\n",
    "                    \"caption\": caption,\n",
    "                    \"sticker\": sticker_name,\n",
    "                })\n",
    "\n",
    "            batch_images = []\n",
    "            batch_paths = []\n",
    "\n",
    "# finish last partial batch\n",
    "if batch_images:\n",
    "    prompts = [\"Describe this icon in detail.\"] * len(batch_images)\n",
    "    captions = annotate_batch_llava(batch_images, prompts)\n",
    "    for (out_filename, orig_name), caption in zip(batch_paths, captions):\n",
    "        all_metadata.append({\n",
    "            \"image\": out_filename,\n",
    "            \"original_frame\": orig_name,\n",
    "            \"caption\": caption,\n",
    "            \"sticker\": sticker_name,\n",
    "        })\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nProcessed {total_images} images in {total_time:.2f} sec\")\n",
    "print(f\"Throughput: {total_images / total_time:.2f} images/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246c5cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "META_PATH = Path(\"../data/icons_metadata.jsonl\")\n",
    "with open(META_PATH, \"w\") as f:\n",
    "    for item in all_metadata:\n",
    "        json_line = json.dumps(item)\n",
    "        f.write(json_line + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icongen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
